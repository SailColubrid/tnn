{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([-1,-1,-1,4,5])\n",
    "a >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[a>0]\n",
    "a[a>0] -= b.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a>=2\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = -1\n",
    "if True in b:\n",
    "    c = np.where(b==True)[0][0]\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Layer():\n",
    "    def __init__(self, layer_id, prev_layer, threshold, receptive_field):\n",
    "        self.layer_id = layer_id\n",
    "        self.prev_layer = prev_layer\n",
    "        self.threshold = threshold\n",
    "        self.rf = receptive_field\n",
    "        #self.N,_,_ = self.prev_layer.raw_data.shape\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the network, clearing out any accumulator variables, etc\n",
    "        pass\n",
    "\n",
    "    def process_image(self):\n",
    "        \"\"\"\n",
    "        This function will control the different processing steps for a\n",
    "        single image\n",
    "\n",
    "        Notice that you can get to values in the previous layer through\n",
    "        self.prev_layer\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def write_spiketimes(self, path, spikes):\n",
    "        # create a file with: image_number, spike_position, spike_time\n",
    "        i = 0\n",
    "        f = open(path, \"a\")\n",
    "        f.write('img_number'+','+'spike position'+','+'spike time\\n')\n",
    "        for x in spikes:\n",
    "            st =''\n",
    "            for spike_time in x:\n",
    "                st += str(spike_time) if spike_time != -1 else '-'\n",
    "            f.write(str(i)+','+\"(12 12)to(14 14)\"+','+st+'\\n')\n",
    "            i += 1\n",
    "        f.close()\n",
    "        print (\"Finish writing spike times to \"+path)\n",
    "\n",
    "class Excitatory_Nueron(Layer):\n",
    "    def __init__(self, input_dim, layer_id, prev_layer, threshold, receptive_field, initial_weight):\n",
    "        super(Excitatory_Nueron, self).__init__(layer_id, prev_layer, threshold, receptive_field)\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = initial_weight\n",
    "        self.wave = np.zeros(input_dim)\n",
    "        self.input = np.array([[1,2,4,3,1], [3,4,5,5,1], [0,3,1,2,3]])\n",
    "        self.reset()\n",
    "        #self.input = self.prev_layer.output\n",
    "    \n",
    "    def reset(self):\n",
    "        self.wave = np.zeros(self.input_dim)\n",
    "        self.FireFlag = 0\n",
    "\n",
    "    def process_image(self):\n",
    "        \"\"\"\n",
    "        Step funtion funtionality\n",
    "        \"\"\"\n",
    "        self.output=[]\n",
    "        for sample in self.input:\n",
    "            self.reset()\n",
    "            sample = np.sort(sample)\n",
    "            for x in sample:\n",
    "                if x != -1:\n",
    "                    self.wave[x:] += self.weight\n",
    "                diff = self.wave > self.threshold\n",
    "                if True in diff:\n",
    "                    self.output.append(np.where(diff == True)[0][0])\n",
    "                    self.FireFlag += 1\n",
    "                    break\n",
    "            if not self.FireFlag:\n",
    "                self.output.append(-1)\n",
    "        self.output = np.asarray(self.output)[:,None]\n",
    "        return self.output\n",
    "\n",
    "class Excitatory_Layer(Layer):\n",
    "    def __init__(self, input_dim, output_dim, layer_id, prev_layer, threshold, receptive_field, initial_weight):\n",
    "        super(Excitatory_Layer, self).__init__(layer_id, prev_layer, threshold, receptive_field)\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = initial_weight\n",
    "        self.output = None\n",
    "        self.neurons = [Excitatory_Nueron(input_dim=input_dim, \n",
    "                                          layer_id=layer_id, \n",
    "                                          prev_layer=prev_layer, \n",
    "                                          threshold=threshold, \n",
    "                                          receptive_field=receptive_field, \n",
    "                                          initial_weight=initial_weight)] * output_dim\n",
    "\n",
    "    def reset(self):\n",
    "        for i in range(len(self.neurons)):\n",
    "            self.neurons[i].reset()\n",
    "    \n",
    "    def process_image(self):\n",
    "        output = []\n",
    "        for i in range(len(self.neurons)):\n",
    "            output.append(self.neurons[i].process_image())\n",
    "        self.output = np.concatenate(output, axis=1)\n",
    "        return self.output\n",
    "    \n",
    "    \n",
    "class Winner_Take_All_Layer(Layer):\n",
    "    def __init__(self, layer_id, prev_layer, threshold, receptive_field):\n",
    "        super(Winner_Take_All_Layer, self).__init__(layer_id, prev_layer, threshold, receptive_field)\n",
    "        self.input = prev_layer.output\n",
    "        self.output = []\n",
    "    def process_image(self, mode = 'LowPass'):\n",
    "        \"\"\"\n",
    "        Winner take all functionality\n",
    "        \"\"\"\n",
    "\n",
    "        for sample in self.input:\n",
    "            min_spike = np.min(sample)\n",
    "            for x in sample:\n",
    "                if (x == min_spike):\n",
    "                    output = min_spike\n",
    "                else:\n",
    "                    output = -1\n",
    "                self.output.append(output)\n",
    "        self.output = np.asarray(self.output)\n",
    "        return self.output.reshape((self.input.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC = Excitatory_Layer(5, 16, 1, None, 3, None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (EC.process_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WTA = Winner_Take_All_Layer(0, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WTA.process_image().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from layer import Inhibitory_Layer as IL\n",
    "from layer import Excitatory_Layer as EL\n",
    "from layer import LateralInhibiton_Layer as LL\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import firstlayer as firstlayer\n",
    "import layer as layer\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "N, _ = mnist.data.shape\n",
    "\n",
    "# Reshape the data to be square\n",
    "mnist.square_data = mnist.data.reshape(N,28,28)\n",
    "layer1 = firstlayer.FirstLayer(1)\n",
    "# You will need to change the instantiation of this layer\n",
    "# in order to properly initialize a new layer\n",
    "layer2 = IL(layer_id=1, \n",
    "            prev_layer=layer1, \n",
    "            threshold=3, \n",
    "            receptive_field=12)\n",
    "\n",
    "layer3 = EL(input_dim=8, \n",
    "            output_dim=16, \n",
    "            layer_id=3, \n",
    "            prev_layer=layer2, \n",
    "            threshold=2,  \n",
    "            initial_weight=1)\n",
    "layer4 = LL(layer_id=4, \n",
    "            prev_layer=layer3, \n",
    "            threshold=None, \n",
    "            receptive_field=None)\n",
    "\n",
    "\n",
    "\n",
    "x1 = layer1.forward(mnist.square_data[-10:], 12)\n",
    "x2 = layer2.forward(x1, mode='Exact')\n",
    "x3 = layer3.forward(x2)\n",
    "x4 = layer4.forward(data=x3)\n",
    "print (x1)\n",
    "print (x2)\n",
    "print (x3)\n",
    "print (x4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WMAX = 7\n",
    "def stdp_update_rule(layer, winning_spiketime, update_probability=1/32):\n",
    "    '''\n",
    "    Arguments:\n",
    "    Input: \n",
    "        layer: weights of which layer you wanna do stdp update\n",
    "        winning_spiketime: spikestimes after WTA\n",
    "        update_probability: weight update probability\n",
    "    Return:\n",
    "        updated_layer: The layer whose weights are updated\n",
    "    '''\n",
    "\n",
    "    prev_layer_ouput = layer.prev_layer.output\n",
    "    neuron_spiketime = layer.output\n",
    "    num_of_imput = prev_layer_ouput.shape[0]\n",
    "\n",
    "    for i in range(num_of_imput): # update for each input\n",
    "        for j in range(len(layer.neurons)): # iterate across each neuron\n",
    "            input_spikes = prev_layer_ouput[i]\n",
    "            output_spikes = True if neuron_spiketime[i][j] > -1 else False\n",
    "            pre_inhibition = True if winning_spiketime[i][j] > -1 else False\n",
    "\n",
    "            if output_spikes:\n",
    "                for k in range(len(layer.neurons[j].weight)): # update each weight, respectively\n",
    "                    if input_spikes[k] > -1: #if input\n",
    "                        if winning_spiketime[i][j] >= input_spikes[k]: \n",
    "                            layer.neurons[j].weight[k] = WMAX\n",
    "                        else:\n",
    "                            layer.neurons[j].weight[k] = 0\n",
    "                    else:\n",
    "                        layer.neurons[j].weight[k] = 0\n",
    "            else:\n",
    "                for k in range(len(layer.neurons[j].weight)): # update each weight, respectively\n",
    "                    if pre_inhibition and input_spikes[k] > -1:\n",
    "                        layer.neurons[j].weight[k] = 0\n",
    "                    elif not pre_inhibition:\n",
    "                        if input_spikes[k] > -1 and np.random.random_sample()<update_probability:\n",
    "                            layer.neurons[j].weight[k] += 1\n",
    "    for neuron in layer.neurons:\n",
    "        print (neuron.weight)\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron in layer3.neurons:\n",
    "    print (neuron.weight)\n",
    "layer3 = stdp_update_rule(layer3, x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x in layer3.output.sum(axis=1):\n",
    "    if x>-16:\n",
    "        print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (layer3.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos(data):\n",
    "    return sum(n > 0 for n in data)\n",
    "for i in range(output.shape[0]):\n",
    "    if count_pos(output[i]):\n",
    "        temp = output[i]\n",
    "        temp2 = temp[temp>-1]\n",
    "        output[i][output[i]>-1] -= temp2.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([ 5,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
    "       -1])\n",
    "b = a[a>-1]\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LateralInhibiton_Layer(Layer):\n",
    "    def __init__(self, layer_id, prev_layer, threshold, receptive_field):\n",
    "        super(LateralInhibiton_Layer, self).__init__(layer_id, prev_layer, threshold, receptive_field)\n",
    "        self.input = None\n",
    "        self.output = []\n",
    "\n",
    "    def process_image(self, data):\n",
    "        \"\"\"\n",
    "        Step funtion funtionality\n",
    "        \"\"\"\n",
    "        self.output = data\n",
    "        for i, sample in enumerate(self.output):\n",
    "            sign = sample > -1\n",
    "            if True in sign:\n",
    "                pos = sample[sample>-1]\n",
    "                fire_neuron = np.where(sample == pos.min())[0]\n",
    "                self.output[i] += 1\n",
    "                mask = np.zeros(sample.shape[0])\n",
    "                mask[fire_neuron] = 1\n",
    "                self.output[i] = mask * sample\n",
    "                self.output[i] -= 1\n",
    "        return self.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LI = LateralInhibiton_Layer(0,None,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LI.process_image(np.array([[1,1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before training\r\n",
      "[0 1 2 2 0 3 1 3]\r\n",
      "[1 3 2 0 2 2 2 0]\r\n",
      "[3 3 3 0 2 1 3 2]\r\n",
      "[0 3 2 1 1 0 3 2]\r\n",
      "[2 1 1 0 1 1 1 1]\r\n",
      "[1 1 1 2 0 0 1 2]\r\n",
      "[2 0 0 3 2 1 2 1]\r\n",
      "[2 2 2 2 2 3 0 1]\r\n",
      "[3 3 0 3 1 3 3 1]\r\n",
      "[1 3 2 1 1 2 2 1]\r\n",
      "[2 0 0 1 0 0 3 3]\r\n",
      "[1 0 0 3 3 1 0 3]\r\n",
      "[0 0 1 3 0 1 2 0]\r\n",
      "[3 1 1 2 2 2 2 0]\r\n",
      "[1 0 2 2 2 1 0 1]\r\n",
      "[2 1 3 2 0 2 0 3]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 lab2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before training\n",
      "[0 5 2 6 4 3 5 5]\n",
      "[2 0 6 6 2 0 3 4]\n",
      "[6 5 2 0 3 6 5 5]\n",
      "[0 3 2 2 1 1 0 5]\n",
      "[1 5 1 1 5 5 2 0]\n",
      "[0 1 2 6 0 4 6 1]\n",
      "[6 5 2 2 2 6 6 3]\n",
      "[0 5 3 4 3 5 3 5]\n",
      "[5 3 6 5 1 6 2 1]\n",
      "[6 4 4 5 4 0 3 3]\n",
      "[1 0 0 3 5 0 0 0]\n",
      "[5 3 0 1 2 4 3 1]\n",
      "[1 6 6 6 2 0 5 0]\n",
      "[6 6 6 1 0 1 2 1]\n",
      "[6 4 2 4 3 0 4 0]\n",
      "[6 6 4 6 0 1 2 4]\n",
      "Traceback (most recent call last):\n",
      "  File \"lab2.py\", line 60, in <module>\n",
      "    layer3 = stdp_update_rule(layer3, x4)\n",
      "  File \"/Users/wangzifan/Documents/CMU/18-847/lab3/layer.py\", line 24, in stdp_update_rule\n",
      "    num_of_input = prev_layer_ouput.shape[0]\n",
      "NameError: name 'prev_layer_ouput' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python3 lab2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[0, -1, -1], [-1, 1, -1]])\n",
    "a = a > -1\n",
    "for sample in a:\n",
    "    if True in sample:\n",
    "        print (np.where(sample==True)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "N, _ = mnist.data.shape\n",
    "np.random.seed(2)\n",
    "shuffledindex = np.random.permutation([i for i in (range(N))])\n",
    "mnistdata = mnist.data[shuffledindex]\n",
    "mnisttarget = mnist.target[shuffledindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnisttarget[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0, 1, -1])\n",
    "\n",
    "np.random.choice(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
